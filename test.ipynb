{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm \n",
    "from torch.utils.data import TensorDataset\n",
    "import faiss\n",
    "import numpy as np \n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pickle\n",
    "from process_data import load_data_split, get_candidate_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dictionary(dictionary_path): \n",
    "    ids = []\n",
    "    names = []\n",
    "    with open(dictionary_path,'r') as f: \n",
    "        for line in f: \n",
    "            line = line.strip().split('||') \n",
    "            ids.append(line[0])\n",
    "            names.append(line[1])\n",
    "    return ids,names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "biosyn_path = \"/share/project/biomed/hcd/BioSyn/pretrained/biosyn-sapbert-bc5cdr-chemical\"\n",
    "train_data = load_data_split(\"./data/bc5cdr-c_v1/processed/train.jsonl\")\n",
    "val_data = load_data_split(\"./data/bc5cdr-c_v1/processed/val.jsonl\")\n",
    "test_data = load_data_split(\"./data/bc5cdr-c_v1/processed/test.jsonl\")\n",
    "#entities = load_entities(\"./data/bc5cdr-c_v1/entity_documents.json\")\n",
    "path = \"/share/project/biomed/hcd/BioSyn/datasets/bc5cdr-chemical/train_dictionary.txt\"\n",
    "train_dict_ids, train_dict_names = load_dictionary(path)\n",
    "# train_dict_ids = train_dict_ids[:100]\n",
    "# train_dict_names = train_dict_names[:100]\n",
    "path = \"/share/project/biomed/hcd/BioSyn/datasets/bc5cdr-chemical/dev_dictionary.txt\"\n",
    "val_dict_ids, val_dict_names = load_dictionary(path)\n",
    "# val_dict_ids = val_dict_ids[:100]\n",
    "# val_dict_names = val_dict_names[:100]\n",
    "path = \"/share/project/biomed/hcd/BioSyn/datasets/bc5cdr-chemical/test_dictionary.txt\"\n",
    "test_dict_ids, test_dict_names = load_dictionary(path)\n",
    "# test_dict_ids = test_dict_ids[:100]\n",
    "# test_dict_names = test_dict_names[:100]\n",
    "biosyn = BertModel.from_pretrained(biosyn_path)\n",
    "\n",
    "biosyn_tokenizer = BertTokenizer.from_pretrained(biosyn_path)\n",
    "\n",
    "biobert_tokenizer = BertTokenizer.from_pretrained(\"/share/project/biomed/hcd/arboEL/models/biobert-base-cased-v1.1\")\n",
    "device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "\n",
    "biosyn = biosyn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_entity_dictionary(ids, names, tokenizer, biobert_tokenizer, dictionary_processed = True):\n",
    "    ## tokenizer has to be biosyn tokenizer\n",
    "    idx_to_id = {}\n",
    "    id_to_idx = {}\n",
    "    entity_dictionary = []\n",
    "    with torch.no_grad():\n",
    "        for idx, (id_, name) in enumerate(zip(ids,names)):\n",
    "            print(idx,end='\\r')\n",
    "            #id_to_idx[id_] = idx\n",
    "            idx_to_id[idx] = id_\n",
    "            if id_ not in id_to_idx:\n",
    "                id_to_idx[id_] = []\n",
    "            id_to_idx[id_].append(idx)\n",
    "            if not dictionary_processed:\n",
    "                #label_representation = get_candidate_representation(name.lower(), tokenizer)\n",
    "                biobert_representation = get_candidate_representation(name.lower(),biobert_tokenizer)\n",
    "                entity_dictionary.append({\n",
    "                    # \"tokens\": label_representation[\"tokens\"],\n",
    "                    # \"ids\": label_representation[\"ids\"],\n",
    "                    \"biobert_tokens\": biobert_representation[\"tokens\"],\n",
    "                    \"biobert_ids\": biobert_representation[\"ids\"]\n",
    "                }) \n",
    "                \n",
    "                \n",
    "    return id_to_idx, idx_to_id, entity_dictionary\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407599\r"
     ]
    }
   ],
   "source": [
    "train_id2idx, train_idx2id, train_dictionary = process_entity_dictionary(train_dict_ids, train_dict_names, biosyn_tokenizer, biobert_tokenizer)\n",
    "# with open(\"./data/bc5cdr-c_v1/processed/train/idx2id.pkl\",'wb') as handle:\n",
    "#     pickle.dump(train_idx2id, handle)\n",
    "    \n",
    "# with open(\"./data/bc5cdr-c_v1/processed/train/id2idx.pkl\",'wb') as handle:\n",
    "#     pickle.dump(train_id2idx, handle)\n",
    "\n",
    "with open(\"./data/bc5cdr-c_v1/processed/train/biobert_dict.pkl\", 'wb') as write_handle:\n",
    "                    pickle.dump(train_dictionary, write_handle,\n",
    "                                protocol=pickle.HIGHEST_PROTOCOL)\n",
    "val_id2idx, val_idx2id, val_dictionary = process_entity_dictionary(val_dict_ids, val_dict_names, biosyn_tokenizer, biobert_tokenizer)\n",
    "# with open(\"./data/bc5cdr-c_v1/processed/val/idx2id.pkl\",'wb') as handle:\n",
    "#     pickle.dump(val_idx2id, handle)\n",
    "# with open(\"./data/bc5cdr-c_v1/processed/val/id2idx.pkl\",'wb') as handle:\n",
    "#     pickle.dump(val_id2idx, handle)\n",
    "\n",
    "with open(\"./data/bc5cdr-c_v1/processed/val/biobert_dict.pkl\", 'wb') as write_handle:\n",
    "                    pickle.dump(val_dictionary, write_handle,\n",
    "                                protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                    \n",
    "test_id2idx, test_idx2id, test_dictionary = process_entity_dictionary(test_dict_ids, test_dict_names, biosyn_tokenizer, biobert_tokenizer)\n",
    "# with open(\"./data/bc5cdr-c_v1/processed/test/idx2id.pkl\",'wb') as handle:\n",
    "#     pickle.dump(test_idx2id, handle)\n",
    "# with open(\"./data/bc5cdr-c_v1/processed/test/id2idx.pkl\",'wb') as handle:\n",
    "#     pickle.dump(test_id2idx, handle)\n",
    "with open(\"./data/bc5cdr-c_v1/processed/test/biobert_dict.pkl\", 'wb') as write_handle:\n",
    "                    pickle.dump(test_dictionary, write_handle,\n",
    "                                protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407600 407454 407247\n"
     ]
    }
   ],
   "source": [
    "print(len(test_idx2id),len(val_idx2id), len(train_idx2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating embeddings: 100%|██████████| 100/100 [00:00<00:00, 144.90it/s]\n",
      "calculating embeddings: 100%|██████████| 100/100 [00:00<00:00, 145.40it/s]\n",
      "calculating embeddings: 100%|██████████| 100/100 [00:00<00:00, 146.44it/s]\n"
     ]
    }
   ],
   "source": [
    "def embed_dictionary(model, device,  entity_dictionary):\n",
    "    ent_embs = [] \n",
    "    with torch.no_grad():\n",
    "        for idx, ent in enumerate(tqdm(entity_dictionary[:100], desc = \"calculating embeddings\")):\n",
    "            input = torch.tensor(ent['ids'])\n",
    "            #print(input.shape)\n",
    "            emb = model(input[None,:].to(device))[0].mean(1).squeeze(0)\n",
    "            #print(emb.shape)\n",
    "            ent_embs.append(emb.cpu())\n",
    "    ent_embs = torch.stack(ent_embs)\n",
    "    \n",
    "    return ent_embs\n",
    "\n",
    "train_ent_embs = embed_dictionary(biosyn, device, train_dictionary)\n",
    "torch.save(train_ent_embs, './data/bc5cdr-c_v1/processed/train/dictionary_embs.pt')\n",
    "val_ent_embs = embed_dictionary(biosyn, device, val_dictionary)\n",
    "torch.save(val_ent_embs, './data/bc5cdr-c_v1/processed/val/dictionary_embs.pt')\n",
    "\n",
    "test_ent_embs = embed_dictionary(biosyn, device, test_dictionary)\n",
    "torch.save(test_ent_embs, './data/bc5cdr-c_v1/processed/test/dictionary_embs.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating embeddings: 100%|██████████| 5157/5157 [00:52<00:00, 97.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8413806476633702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating embeddings: 100%|██████████| 5302/5302 [00:53<00:00, 99.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8647680120709166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating embeddings: 100%|██████████| 5351/5351 [00:53<00:00, 99.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8346103532050084\n"
     ]
    }
   ],
   "source": [
    "def get_candidates(mention_samples, model, device, entity_embs, id2idx, idx2id, n_candidates, tokenizer, split, debug=False):\n",
    "    ### id2idx is the one we got from process_entity_dictionary. e.g. D1234 -> idx\n",
    "    ### here entity_dictionary is entity_documents.json\n",
    "    ### here mention_samples is e.g. train.jsonl\n",
    "    id2emb = {}\n",
    "    d = 768\n",
    "    res = faiss.StandardGpuResources()\n",
    "    index_flat = faiss.IndexFlatL2(d)\n",
    "    gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index_flat)\n",
    "    gpu_index_flat.add(entity_embs)\n",
    "    count = 0\n",
    "    targets = []\n",
    "    neighbor_list = []\n",
    "    #embs = torch.load('')\n",
    "    for idx, sample in enumerate(tqdm(mention_samples, desc = \"calculating embeddings\")):\n",
    "            with torch.no_grad():\n",
    "                mention_representation = get_candidate_representation(sample['mention'].lower(), tokenizer)\n",
    "                mention_ids = mention_representation['ids']\n",
    "                input = torch.tensor(mention_ids)\n",
    "                emb = model(input[None,:].to(device))[0].mean(1)\n",
    "            #emb = entity_embs[idx]\n",
    "            #print(sample.keys())\n",
    "            mention_label = sample['label_id']\n",
    "            \n",
    "                \n",
    "            #print(mention_label_idx)\n",
    "            #print(sample)\n",
    "            emb = emb.cpu()\n",
    "            #print(emb.shape)\n",
    "            #idx2id = {v: k for k, v in id2idx.items()}\n",
    "            id2emb[sample['mention_id']] = emb\n",
    "            #top_k = n_candidates\n",
    "            \n",
    "            D, I = gpu_index_flat.search(emb, n_candidates)\n",
    "            result = I[0]\n",
    "            neighbor_ids = [idx2id[k] for k in result]\n",
    "            if split == \"train\":\n",
    "                if mention_label not in neighbor_ids:\n",
    "                    if mention_label in id2idx:\n",
    "                        mention_label_idx = id2idx[mention_label][0]\n",
    "                        np.concatenate([[mention_label_idx], result])\n",
    "                    \n",
    "            neighbor_ids = [idx2id[k] for k in result]\n",
    "            if mention_label in neighbor_ids:\n",
    "                count +=1\n",
    "            target = []\n",
    "            \n",
    "            for id_ in neighbor_ids:\n",
    "                if id_ == mention_label:\n",
    "                    target.append(1)\n",
    "                else:\n",
    "                    target.append(0)\n",
    "            \n",
    "            targets.append(target[0:n_candidates])\n",
    "            neighbor_list.append(result[0:n_candidates])\n",
    "       \n",
    "    print(count/len(mention_samples))\n",
    "    return neighbor_list, targets\n",
    "n_candidates = 64\n",
    "train_ent_embs = torch.load(\"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/train/dictionary_embs.pt\")\n",
    "with open(\"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/train/idx2id.pkl\",'rb') as f:\n",
    "    train_idx2id = pickle.load(f)\n",
    "with open(\"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/train/id2idx.pkl\",'rb') as f:\n",
    "    train_id2idx = pickle.load(f)\n",
    "# with open(\"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/train_dict.pkl\",'rb') as f:\n",
    "#     train_dict= pickle.load(f)\n",
    "train_neighbors, train_labels = get_candidates(train_data, biosyn, device, train_ent_embs, train_id2idx, train_idx2id, n_candidates, biosyn_tokenizer, 'train')\n",
    "np.save('./data/bc5cdr-c_v1/processed/train/neighbors.npy', train_neighbors)\n",
    "np.save('./data/bc5cdr-c_v1/processed/train/neighbor_labels.npy', train_labels)\n",
    "\n",
    "val_ent_embs = torch.load(\"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/val/dictionary_embs.pt\")\n",
    "with open(\"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/val/idx2id.pkl\",'rb') as f:\n",
    "    val_idx2id = pickle.load(f)\n",
    "with open(\"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/val/id2idx.pkl\",'rb') as f:\n",
    "    val_id2idx = pickle.load(f)\n",
    "# with open(\"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/val/dict.pkl\",'rb') as f:\n",
    "#     val_dict= pickle.load(f)\n",
    "val_neighbors, val_labels = get_candidates(val_data, biosyn, device, val_ent_embs, val_id2idx, val_idx2id, n_candidates, biosyn_tokenizer, 'val')\n",
    "np.save('./data/bc5cdr-c_v1/processed/val/neighbors.npy', val_neighbors)\n",
    "np.save('./data/bc5cdr-c_v1/processed/val/neighbor_labels.npy', val_labels)\n",
    "\n",
    "test_ent_embs = torch.load(\"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/test/dictionary_embs.pt\")\n",
    "with open(\"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/test/idx2id.pkl\",'rb') as f:\n",
    "    test_idx2id = pickle.load(f)\n",
    "with open(\"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/test/id2idx.pkl\",'rb') as f:\n",
    "    test_id2idx = pickle.load(f)\n",
    "# with open(\"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/test/dict.pkl\",'rb') as f:\n",
    "#     train_dict= pickle.load(f)\n",
    "test_neighbors, test_labels = get_candidates(test_data, biosyn, device, test_ent_embs, test_id2idx, test_idx2id, n_candidates, biosyn_tokenizer, 'test')\n",
    "np.save('./data/bc5cdr-c_v1/processed/test/neighbors.npy', test_neighbors)\n",
    "np.save('./data/bc5cdr-c_v1/processed/test/neighbor_labels.npy', test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([209117, 209115, 297590, 209109, 209120, 385224, 384097, 209098,\n",
       "       222391, 396693, 269771, 209100, 170623, 169043, 240858,  85215,\n",
       "       270275, 131578, 336778, 121046, 276018, 367136, 338993, 337386,\n",
       "       237454, 367056, 235127, 223937, 364547, 169042, 268553, 192206,\n",
       "       390510, 336806, 255057, 189925, 263709, 371793, 231227, 398031,\n",
       "       249123, 223609, 396111, 188149, 246124, 384096, 207327, 209136,\n",
       "       328969, 202296,   5139, 137546, 113842, 269797, 128230, 382096,\n",
       "       160194, 125115, 340852, 222794, 237453, 226018, 367775, 308691])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_neighbors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm, trange\n",
    "#import numpy as np\n",
    "from biencoder import BiEncoderRanker\n",
    "#from process_data import load_data_split\n",
    "import pickle\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logger(name, log_file, level=logging.INFO):\n",
    "    \"\"\"To setup as many loggers as you want\"\"\"\n",
    "    formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "    handler = logging.FileHandler(log_file, mode='a')        \n",
    "    handler.setFormatter(formatter)\n",
    "\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    consoleHandler = logging.StreamHandler()\n",
    "    consoleHandler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(consoleHandler)\n",
    "    return logger\n",
    "\n",
    "def calculate_accuracy(max_idxs, correct):\n",
    "    #acc = 0\n",
    "    for idx in max_idxs:\n",
    "        if idx == 0:\n",
    "           correct+=1\n",
    "    return correct\n",
    "\n",
    "def evaluate(reranker, val_dataloader, criterion, entities, neighbors, labels, device, logger):\n",
    "    reranker.model.eval()\n",
    "    total_samples = 0\n",
    "    correct = 0\n",
    "    loss_list = []\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(tqdm(val_dataloader,desc=\"validation mini batches\")):\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                mention_idxs, context_ids = batch    \n",
    "                candidate_ids = []\n",
    "                \n",
    "                for idx in mention_idxs:\n",
    "                    candidate_ids.append([])\n",
    "                    for neighbor in neighbors[idx]:\n",
    "                        candidate_ids[-1].append(entities[neighbor]['biobert_ids'])\n",
    "                \n",
    "                candidate_ids = torch.tensor(candidate_ids).to(device)\n",
    "                #print(candidate_ids.shape)\n",
    "                scores = reranker(context_ids, candidate_ids, device) \n",
    "                total_samples += scores.shape[0]\n",
    "                \n",
    "                labels = torch.FloatTensor(labels,device)\n",
    "                max_idxs = scores.argmax(dim=1)\n",
    "                correct = calculate_accuracy(max_idxs, correct)\n",
    "                probs = F.softmax(scores, dim=1)\n",
    "\n",
    "                #p_correct = probs[:, 0]\n",
    "                \n",
    "                loss = criterion(probs, labels)\n",
    "                \n",
    "                loss_list.append(loss.item())\n",
    "\n",
    "    logger.info(\"Evaluation completed, with total samples: {}\".format(total_samples))           \n",
    "    return sum(loss_list)/len(loss_list), correct/total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(path):\n",
    "    with open(path,'rb') as handle:\n",
    "        pkl = pickle.load(handle)\n",
    "    return pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/project/biomed/envs/zeshel/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "from biencoder import BiEncoderRanker\n",
    "import pickle\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "from process_data import get_context_representation\n",
    "import logging\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_field(data, key1, key2=None):\n",
    "    if key2 is None:\n",
    "        return [example[key1] for example in data]\n",
    "    else:\n",
    "        return [example[key1][key2] for example in data]\n",
    "def process_mention_data(samples, tokenizer, id_to_idx, debug = False, max_length=512):\n",
    "    processed_samples = []\n",
    "    print(\"len of id2idx\", len(id_to_idx))\n",
    "    if debug:\n",
    "        print(\"reducing sample size\")\n",
    "        samples = samples[:300]\n",
    "    not_added = 0\n",
    "    #mention_idxs = []\n",
    "    for idx, sample in enumerate(tqdm(samples, desc = \"Tokenizing mentions\")):\n",
    "        context = get_context_representation(sample, tokenizer)\n",
    "        label_id = sample['label_id']\n",
    "        \n",
    "        try:\n",
    "            record = {\n",
    "                \"mention\": sample['mention'],\n",
    "                \"context_tokens\": context['tokens'],\n",
    "                \"context_ids\": context['ids'],\n",
    "                \"mention_idx\": idx,\n",
    "                \"mention_id\":sample['mention_id'],\n",
    "                #\"label_title\": sample['label_title'],\n",
    "                \"label_title\": sample['label'],\n",
    "                \"label_id\":sample['label_id'],\n",
    "                \"label_idxs\": id_to_idx[sample['label_id']]\n",
    "                \n",
    "            }\n",
    "            processed_samples.append(record)\n",
    "        except:\n",
    "            not_added +=1\n",
    "        \n",
    "        \n",
    "        #print(processed_samples)\n",
    "    print(\"not added, due to inconsistency:\",not_added)\n",
    "    context_tensors = torch.tensor(\n",
    "        select_field(processed_samples, \"context_ids\"), dtype=torch.long\n",
    "    )\n",
    "    print(context_tensors.shape)\n",
    "    #print(\"processed_samples label idxs\",processed_samples['label_idxs'].shape)\n",
    "    mentiond_idxs = torch.tensor(\n",
    "        select_field(processed_samples, \"mention_idx\"), dtype=torch.long\n",
    "    )\n",
    "    \n",
    "    # label_idxs = torch.tensor(\n",
    "    # select_field(processed_samples, \"label_idxs\"), dtype=torch.long,\n",
    "    # )\n",
    "\n",
    "    tensor_data = TensorDataset(mentiond_idxs, context_tensors)\n",
    "\n",
    "    #return processed_samples, tensor_data\n",
    "    return tensor_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /share/project/biomed/hcd/arboEL/models/biobert-base-cased-v1.1 were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of id2idx 171267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing mentions: 100%|██████████| 5157/5157 [00:24<00:00, 212.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not added, due to inconsistency: 268\n",
      "torch.Size([4889, 512])\n",
      "len of id2idx 171277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing mentions: 100%|██████████| 5302/5302 [00:23<00:00, 221.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not added, due to inconsistency: 275\n",
      "torch.Size([5027, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]2023-05-11 03:32:25,176 INFO Training\n",
      "2023-05-11 03:32:25,176 INFO Training\n",
      "2023-05-11 03:32:25,176 INFO Training\n",
      "2023-05-11 03:32:25,176 INFO Training\n",
      "Processing minibatches:   0%|          | 0/612 [00:00<?, ?it/s]\n",
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8]) torch.Size([8, 512])\n",
      "candidate_ids shape torch.Size([8, 64, 25])\n",
      "context ids shape  torch.Size([8, 512])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 176\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    175\u001b[0m     parameters \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mn_candidates\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m64\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mval_test_batch_size\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m512\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgradient_accumulation_steps\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m32\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdebug\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m1e-6\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbert_model\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39m/share/project/biomed/hcd/arboEL/models/biobert-base-cased-v1.1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mout_dim\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m768\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m20\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moutput_path\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mbiosyn\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m8\u001b[39m,  \u001b[39m\"\u001b[39m\u001b[39mn_gpu\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontrastive\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mpairwise\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mdata_parallel\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mFalse\u001b[39;00m}\n\u001b[0;32m--> 176\u001b[0m     main(parameters)\n",
      "Cell \u001b[0;32mIn[12], line 101\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcandidate_ids shape\u001b[39m\u001b[39m\"\u001b[39m,candidate_ids\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    100\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcontext ids shape \u001b[39m\u001b[39m\"\u001b[39m, context_ids\u001b[39m.\u001b[39mshape)\n\u001b[0;32m--> 101\u001b[0m scores \u001b[39m=\u001b[39m reranker(context_ids, candidate_ids, device) \n\u001b[1;32m    102\u001b[0m total_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m scores\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    103\u001b[0m \u001b[39m## for binary cross entropy loss\u001b[39;00m\n",
      "File \u001b[0;32m/share/project/biomed/envs/zeshel/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/share/project/biomed/hcd/Masked_EL/biencoder.py:72\u001b[0m, in \u001b[0;36mBiEncoderRanker.forward\u001b[0;34m(self, context_ids, candidate_ids, device)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, context_ids, candidate_ids, device):\n\u001b[0;32m---> 72\u001b[0m     context_emb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode_context(context_ids)  \u001b[39m# batch x token length\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     context_emb \u001b[39m=\u001b[39m context_emb\u001b[39m.\u001b[39munsqueeze(\u001b[39m2\u001b[39m)  \u001b[39m# batch x emb size x 1\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     b, n, s \u001b[39m=\u001b[39m candidate_ids\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m/share/project/biomed/hcd/Masked_EL/biencoder.py:61\u001b[0m, in \u001b[0;36mBiEncoderRanker.encode_context\u001b[0;34m(self, context_ids)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode_context\u001b[39m(\u001b[39mself\u001b[39m, context_ids):\n\u001b[0;32m---> 61\u001b[0m     context_embedding, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(context_ids\u001b[39m=\u001b[39;49mcontext_ids)\n\u001b[1;32m     62\u001b[0m     \u001b[39m#print(context_embedding)\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m context_embedding\n",
      "File \u001b[0;32m/share/project/biomed/envs/zeshel/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/share/project/biomed/hcd/Masked_EL/biencoder.py:23\u001b[0m, in \u001b[0;36mBiEncoderModule.forward\u001b[0;34m(self, context_ids, candidate_ids)\u001b[0m\n\u001b[1;32m     21\u001b[0m context_embedding \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m context_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     context_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontext_encoder(context_ids)\n\u001b[1;32m     24\u001b[0m     context_embedding \u001b[39m=\u001b[39m context_embedding[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmean(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     25\u001b[0m candidate_embedding \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/share/project/biomed/envs/zeshel/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/share/project/biomed/envs/zeshel/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:1007\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1007\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[1;32m   1008\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1009\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1010\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m   1011\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1012\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[1;32m   1014\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[1;32m   1015\u001b[0m     embedding_output,\n\u001b[1;32m   1016\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m   1025\u001b[0m )\n\u001b[1;32m   1026\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/share/project/biomed/envs/zeshel/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/share/project/biomed/envs/zeshel/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:231\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    228\u001b[0m         token_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(input_shape, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_ids\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mword_embeddings(input_ids)\n\u001b[1;32m    232\u001b[0m token_type_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[1;32m    234\u001b[0m embeddings \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39m token_type_embeddings\n",
      "File \u001b[0;32m/share/project/biomed/envs/zeshel/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/share/project/biomed/envs/zeshel/lib/python3.8/site-packages/torch/nn/modules/sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    159\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    160\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m/share/project/biomed/envs/zeshel/lib/python3.8/site-packages/torch/nn/functional.py:2199\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2193\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2194\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2195\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2197\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2198\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2199\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper__index_select)"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "def main(params):\n",
    "    \n",
    "    writer = SummaryWriter()\n",
    "    logger = setup_logger('biencoder_logger', './logs/biencoder64.log')\n",
    "    reranker = BiEncoderRanker(params)\n",
    "    \n",
    "    model = reranker.model\n",
    "    optimizer = reranker.optimizer\n",
    "    tokenizer = reranker.tokenizer\n",
    "    device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "    #reranker = reranker.to(device)\n",
    "    #model = model.to(device)\n",
    "    n_gpu = reranker.n_gpu\n",
    "    #biosyn_path = \"/share/project/biomed/hcd/BioSyn/pretrained/biosyn-sapbert-bc5cdr-chemical\"\n",
    "    train_data = load_data_split(\"./data/bc5cdr-c_v1/processed/train.jsonl\")\n",
    "    val_data = load_data_split(\"./data/bc5cdr-c_v1/processed/val.jsonl\")\n",
    "    test_data = load_data_split(\"./data/bc5cdr-c_v1/processed/test.jsonl\")\n",
    "    #entities = load_entities(\"./data/bc5cdr-c_v1/entity_documents.json\")\n",
    "    # biosyn = BertModel.from_pretrained(biosyn_path).to(device)\n",
    "    # biosyn_tokenizer = BertTokenizer.from_pretrained(biosyn_path)\n",
    "    path = \"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/train/id2idx.pkl\"\n",
    "    train_id2idx = load_pickle(path)\n",
    "    #print(train_id2idx['D002216'])\n",
    "    path = \"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/train/biobert_dict.pkl\"\n",
    "    train_entities = load_pickle(path)\n",
    "\n",
    "    # path = \"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/train/dictionary_embs.pt\"\n",
    "    # # train_ent_embs = torch.load(path)\n",
    "    path = \"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/val/id2idx.pkl\"\n",
    "    \n",
    "    val_id2idx = load_pickle(path)\n",
    "    path = \"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/val/biobert_dict.pkl\"\n",
    "    val_entities = load_pickle(path)\n",
    "    # path = \"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/val/dictionary_embs.pt\"\n",
    "    # val_ent_embs = torch.load(path)\n",
    "    \n",
    "    train_tensor_data = process_mention_data(train_data, tokenizer, train_id2idx, params[\"debug\"])\n",
    "    val_tensor_data = process_mention_data(val_data, tokenizer, val_id2idx, params[\"debug\"])\n",
    "    batch_size = params['batch_size']\n",
    "    val_test_batch_size = params[\"val_test_batch_size\"]\n",
    "    train_dataloader = DataLoader(train_tensor_data, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_tensor_data, batch_size = val_test_batch_size, shuffle = True)\n",
    "\n",
    "    num_train_epochs = params['epoch']\n",
    "\n",
    "    n_candidates = params['n_candidates']\n",
    "    \n",
    "    path = \"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/train/neighbors.npy\"\n",
    "\n",
    "    train_neighbors = np.load(path)\n",
    "    path = \"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/train/neighbor_labels.npy\"\n",
    "    train_neighbor_labels = np.load(path)\n",
    "    \n",
    "    \n",
    "    path = \"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/val/neighbors.npy\"\n",
    "    val_neighbors = np.load(path)\n",
    "    path = \"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/val/neighbor_labels.npy\"\n",
    "    val_neighbor_labels = np.load(path)\n",
    "    #reranker = reranker.to(device)\n",
    "    best_val = 0\n",
    "    best_model = None\n",
    "    output = params['output_path']\n",
    "    #n_candidates = params['n_candidates']\n",
    "    #reranker.to(device)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    for epoch_idx in trange(int(num_train_epochs), desc=\"Epoch\"):\n",
    "        model.train()\n",
    "        logger.info(\"Training\")\n",
    "        #torch.cuda.empty_cache()\n",
    "        gradient_accumulation_steps = 16\n",
    "        loss_list = []\n",
    "        correct = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc = \"Processing minibatches\")):\n",
    "            #optimizer.zero_grad()\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            mention_idxs, context_ids = batch    \n",
    "            candidate_ids = []\n",
    "            print(mention_idxs.shape, context_ids.shape)\n",
    "            # for idx in label_idxs:\n",
    "            #     candidate_ids.append([])\n",
    "      \n",
    "            #     for neighbor in train_neighbors[idx]:\n",
    "   \n",
    "            #         candidate_ids[-1].append(train_entities[neighbor]['ids'])\n",
    "            for idx in mention_idxs:\n",
    "                candidate_ids.append([])\n",
    "                for neighbor in train_neighbors[idx]:\n",
    "                    candidate_ids[-1].append(train_entities[neighbor]['biobert_ids'])\n",
    "                    \n",
    "            \n",
    "            #context_ids = context_ids.to(device)\n",
    "            candidate_ids = torch.tensor(candidate_ids).to(device)\n",
    "            print(\"candidate_ids shape\",candidate_ids.shape)\n",
    "            print(\"context ids shape \", context_ids.shape)\n",
    "            scores = reranker(context_ids, candidate_ids, device) \n",
    "            total_samples += scores.shape[0]\n",
    "            ## for binary cross entropy loss\n",
    "            train_labels = torch.FloatTensor(train_neighbor_labels, device)\n",
    "           \n",
    "                \n",
    "            # target = torch.zeros_like(scores)\n",
    "            # target[:,0] = 1\n",
    "            # target = target.float().to(device)\n",
    "            \n",
    "            # print(train_labels.shape)\n",
    "            # probs = F.softmax(scores, dim=1)\n",
    "            # loss =criterion(probs, train_labels)\n",
    "            # max_idxs = scores.argmax(dim=1)\n",
    "            # correct = calculate_accuracy(max_idxs, correct)\n",
    "           \n",
    "            \n",
    "            if params['data_parallel']:\n",
    "                loss.mean().backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                \n",
    "            if (step+1) % gradient_accumulation_steps == 0 or (step+1) == len(train_dataloader):\n",
    "                loss_list.append(loss.item())\n",
    "                logger.info(\"step: {}, accuracy: {}\".format(step, correct/total_samples))\n",
    "                loss = loss/gradient_accumulation_steps\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                \n",
    "        logger.info(\"Training completed, with total samples: {}\".format(total_samples))    \n",
    "        logger.info(\"Training, epoch: {}, loss_list: {}, epoch_loss: {}, accuracy: {}\".format(epoch_idx,loss_list, sum(loss_list)/len(loss_list), correct/total_samples))\n",
    "        writer.add_scalar(\"Trainining loss/epoch 64 candidates\", sum(loss_list)/len(loss_list), epoch_idx)\n",
    "        \n",
    "        writer.add_scalar(\"Training accuracy/epoch 64 candidates\", correct/total_samples, epoch_idx)\n",
    "        logger.info(\"Evaluating\") \n",
    "        validation_loss, validation_accuracy = evaluate(reranker,val_dataloader, criterion, val_entities,val_neighbors,val_neighbor_labels, device, logger)\n",
    "\n",
    "        logger.info(\"Validation, epoch: {}, loss: {}, accuracy: {}\".format(epoch_idx, validation_loss, validation_accuracy))\n",
    "        \n",
    "        writer.add_scalar(\"Validation loss/epoch 64 candidates\", validation_loss, epoch_idx)\n",
    "        writer.add_scalar(\"Validation accuracy/epoch 64 candidates\", validation_accuracy, epoch_idx)\n",
    "        \n",
    "        # if validation_accuracy > best_val:\n",
    "        #     best_val = validation_accuracy\n",
    "        #     best_model = {'model': model.state_dict(),\n",
    "        #       'optimizer': optimizer.state_dict()}\n",
    "        #     if not os.path.exists('./model_ckpts/'+output):\n",
    "        #         os.makedirs('./model_ckpts/'+output)\n",
    "        #     torch.save(best_model, './model_ckpts/'+output+'/best_model.pt')\n",
    "            \n",
    "        # if (epoch_idx+1)%10 == 0:\n",
    "        #     checkpoint = {'model': model.state_dict(),\n",
    "        #       'optimizer': optimizer.state_dict()}\n",
    "        #     torch.save(checkpoint, './model_ckpts/'+output+'/model_ckpt_'+str(epoch_idx)+'.pt')\n",
    "            \n",
    "    logger.info(\"Evaluating on test set\")    \n",
    "    \n",
    "    path = \"/share/project/biomed/hcd/Masked_EL/data/bc5cdr-c_v1/processed/test/dict.pkl\"\n",
    "    test_entities = load_pickle(path)\n",
    "    test_tensor_data = process_mention_data(test_data, tokenizer, test_id2idx, params['evaluation'], params[\"debug\"])\n",
    "    test_dataloader = DataLoader(test_tensor_data, batch_size = val_test_batch_size, shuffle = False)\n",
    "    test_loss, test_accuracy = evaluate(reranker,test_dataloader, criterion, test_entities, test_neighbors, device, logger)\n",
    "    logger.info(\"Evaluation loss: {}, Accuracy: {}\".format(test_loss, test_accuracy))\n",
    "    # writer.add_scalar(\"Test loss\", test_loss)\n",
    "    # writer.add_scalar(\"Test accuracy\", test_accuracy)\n",
    "    \n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    \n",
    "     \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parameters = {\"n_candidates\":64, \"val_test_batch_size\":512, \"gradient_accumulation_steps\":32, \"debug\":False, \"learning_rate\":1e-6, \"bert_model\":\"/share/project/biomed/hcd/arboEL/models/biobert-base-cased-v1.1\", \"out_dim\":768, \"epoch\":20, \"output_path\":\"biosyn\", \"batch_size\":8,  \"n_gpu\":1, \"contrastive\":False, \"pairwise\":False, \"data_parallel\":False}\n",
    "    main(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'D002188'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m./data/bc5cdr-c/processed/dictionary/id2idx.pkl\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     my_dict \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m----> 5\u001b[0m \u001b[39mprint\u001b[39m(my_dict[\u001b[39m'\u001b[39;49m\u001b[39mD002188\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'D002188'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('./data/bc5cdr-c/processed/dictionary/id2idx.pkl','rb') as f:\n",
    "    my_dict = pickle.load(f)\n",
    "print(my_dict['D002188'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeshel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
